{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    "import _pickle as cPickle\n",
    "import boto3\n",
    "import pandas as pd\n",
    "from tensorflow.python.data import Dataset\n",
    "import boto3.session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "featureVectorSize = 140\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = '{:.1f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def construct_feature_columns():\n",
    "    \"\"\"Construct the TensorFlow Feature Columns.\n",
    "    Returns:\n",
    "      A set of feature columns\n",
    "    \"\"\"\n",
    "    return set([tf.feature_column.numeric_column('audioFeatures', shape=featureVectorSize)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_training_input_fn(features, labels, batch_size, num_epochs=None, shuffle=True):\n",
    "    \"\"\"A custom input_fn for sending our feature vectors to the estimator for training.\n",
    "    Args:\n",
    "      features: The training features.\n",
    "      labels: The training labels.\n",
    "      batch_size: Batch size to use during training.\n",
    "    Returns:\n",
    "      A function that returns batches of training features and labels during training.\n",
    "    \"\"\"\n",
    "    def _input_fn(num_epochs=num_epochs, shuffle=True):\n",
    "        idx = np.random.permutation(features.index)\n",
    "        raw_features = {\"audioFeatures\": features.reindex(idx)}\n",
    "        raw_labels = np.array(labels[idx])\n",
    "\n",
    "        ds = Dataset.from_tensor_slices((raw_features, raw_labels))\n",
    "        ds = ds.batch(batch_size).repeat(num_epochs)\n",
    "\n",
    "        if shuffle:\n",
    "            ds = ds.shuffle(10000)\n",
    "\n",
    "        # Returns the next batch of data.\n",
    "        feature_batch, label_batch = ds.make_one_shot_iterator().get_next()\n",
    "        return feature_batch, label_batch\n",
    "\n",
    "    return _input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_predict_input_fn(features, labels, batch_size):\n",
    "    \"\"\"A custom input_fn for sending our feature vectors to the estimator for predictions.\n",
    "    Args:\n",
    "      features: The features to base predictions on.\n",
    "      labels: The labels of the prediction examples.\n",
    "    Returns:\n",
    "      A function that returns features and labels for predictions.\n",
    "    \"\"\"\n",
    "\n",
    "    def _input_fn():\n",
    "        raw_features = {\"audioFeatures\": features.values}\n",
    "        raw_labels = np.array(labels)\n",
    "\n",
    "        ds = Dataset.from_tensor_slices((raw_features, raw_labels))\n",
    "        ds = ds.batch(batch_size)\n",
    "\n",
    "        # Returns the next batch of data.\n",
    "        feature_batch, label_batch = ds.make_one_shot_iterator().get_next()\n",
    "        return feature_batch, label_batch\n",
    "\n",
    "    return _input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_nn_classification_model(\n",
    "        learning_rate,\n",
    "        regularization_strength,\n",
    "        steps,\n",
    "        batch_size,\n",
    "        hidden_units,\n",
    "        training_examples,\n",
    "        training_labels,\n",
    "        validation_examples,\n",
    "        validation_labels,\n",
    "        model_Name='no_Name'):\n",
    "    \"\"\"Trains a neural network classification model.\n",
    "    In addition to training, this function also prints training progress information,\n",
    "    a plot of the training and validation loss over time, as well as a confusion\n",
    "    matrix.\n",
    "    Args:\n",
    "      learning_rate: An `int`, the learning rate to use.\n",
    "      regularization_strength: A float, the regularization strength.\n",
    "      steps: A non-zero `int`, the total number of training steps. A training step\n",
    "        consists of a forward and backward pass using a single batch.\n",
    "      batch_size: A non-zero `int`, the batch size.\n",
    "      hidden_units: A `list` of int values, specifying the number of units in each layer.\n",
    "      training_examples: A `DataFrame` containing the training features.\n",
    "      training_labels: A `DataFrame` containing the training labels.\n",
    "      validation_examples: A `DataFrame` containing the validation features.\n",
    "      validation_labels: A `DataFrame` containing the validation labels.\n",
    "      model_Name: A `string` containing the model's name which is used when storing the loss curve and confusion\n",
    "       matrix plots.\n",
    "    Returns:\n",
    "      The trained `DNNClassifier` object.\n",
    "    \"\"\"\n",
    "    periods = 10\n",
    "    steps_per_period = steps / periods\n",
    "\n",
    "    # Create the input functions.\n",
    "    predict_training_input_fn = create_predict_input_fn(\n",
    "        training_examples, training_labels, batch_size)\n",
    "    predict_validation_input_fn = create_predict_input_fn(\n",
    "        validation_examples, validation_labels, batch_size)\n",
    "    training_input_fn = create_training_input_fn(\n",
    "        training_examples, training_labels, batch_size)\n",
    "\n",
    "    # Create feature columns.\n",
    "    feature_columns = construct_feature_columns()\n",
    "\n",
    "    # Create a DNNClassifier object.\n",
    "    my_optimizer = tf.train.ProximalAdagradOptimizer(\n",
    "        learning_rate=learning_rate,\n",
    "        l2_regularization_strength=regularization_strength  # can be swapped for l1 regularization\n",
    "    )\n",
    "\n",
    "    classifier = tf.estimator.DNNClassifier(\n",
    "        feature_columns=feature_columns,\n",
    "        n_classes=10,\n",
    "        hidden_units=hidden_units,\n",
    "        optimizer=my_optimizer,\n",
    "        config=tf.contrib.learn.RunConfig(keep_checkpoint_max=1)\n",
    "    )\n",
    "\n",
    "    # Train the model, but do so inside a loop so that we can periodically assess loss metrics.\n",
    "    print(\"Training model...\")\n",
    "    print(\"LogLoss error (on validation data):\")\n",
    "    training_errors = []\n",
    "    validation_errors = []\n",
    "    \n",
    "    for period in range(0, periods):\n",
    "        # Train the model, starting from the prior state.\n",
    "        print(\"here\")\n",
    "        classifier.train(\n",
    "            input_fn=training_input_fn,\n",
    "            steps=steps_per_period\n",
    "        )\n",
    "\n",
    "        # Use the current model to make predictions on both, the training and validation set.\n",
    "        training_predictions = list(classifier.predict(input_fn=predict_training_input_fn))\n",
    "        training_pred_class_id = np.array([item['class_ids'][0] for item in training_predictions])\n",
    "        training_pred_one_hot = tf.keras.utils.to_categorical(training_pred_class_id, 10)\n",
    "\n",
    "        validation_predictions = list(classifier.predict(input_fn=predict_validation_input_fn))\n",
    "        validation_pred_class_id = np.array([item['class_ids'][0] for item in validation_predictions])\n",
    "        validation_pred_one_hot = tf.keras.utils.to_categorical(validation_pred_class_id, 10)\n",
    "\n",
    "        # Use predictions to compute training and validation errors.\n",
    "        training_log_loss = metrics.log_loss(training_labels, training_pred_one_hot)\n",
    "        validation_log_loss = metrics.log_loss(validation_labels, validation_pred_one_hot)\n",
    "\n",
    "        # Print validation error of current model.\n",
    "        print(\"  period %02d : %0.2f\" % (period, validation_log_loss))\n",
    "\n",
    "        # Store loss metrics so we can plot them later.\n",
    "        training_errors.append(training_log_loss)\n",
    "        validation_errors.append(validation_log_loss)\n",
    "\n",
    "    print(\"Model training finished.\")\n",
    "    # Remove event files to save disk space.\n",
    "    _ = map(os.remove, glob.glob(os.path.join(classifier.model_dir, 'events.out.tfevents*')))\n",
    "\n",
    "    # Compute predictions of final model.\n",
    "    final_predictions = classifier.predict(input_fn=predict_validation_input_fn)\n",
    "    final_predictions = np.array([item['class_ids'][0] for item in final_predictions])\n",
    "\n",
    "    # Evaluate predictions of final model.\n",
    "    accuracy = metrics.accuracy_score(validation_labels, final_predictions)\n",
    "    print(\"Final accuracy (on validation data): %0.2f\" % accuracy)\n",
    "\n",
    "    # Output a graph of loss metrics over periods.\n",
    "    plt.ylabel(\"LogLoss\")\n",
    "    plt.xlabel(\"Periods\")\n",
    "    plt.title(\"LogLoss vs. Periods\")\n",
    "    plt.plot(training_errors, label=\"training\")\n",
    "    plt.plot(validation_errors, label=\"validation\")\n",
    "    plt.legend()\n",
    "    # plt.show()  # blocks execution\n",
    "    plt.savefig('Results\\\\' + model_Name + '_loss_curve.png', bbox_inches='tight')\n",
    "    plt.gcf().clear()\n",
    "\n",
    "    # Create a confusion matrix.\n",
    "    cm = metrics.confusion_matrix(validation_labels, final_predictions)\n",
    "\n",
    "    # Normalize the confusion matrix by the number of samples in each class (rows).\n",
    "    cm_normalized = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]\n",
    "    ax = sns.heatmap(cm_normalized, cmap=\"bone_r\")\n",
    "    ax.set_aspect(1)\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    # plt.show()  # blocks execution\n",
    "    plt.savefig('Results\\\\' + model_Name + '_confusion_matrix.png', bbox_inches='tight')\n",
    "    plt.gcf().clear()\n",
    "\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_features(dataset_name):\n",
    "    \"\"\"\n",
    "    Unpickles the given examples and labels. Mean normalizes the examples.\n",
    "    :param dataset_name: Pair of names referring to an example and corresponding label set.\n",
    "    :return: Actual dataset as a pair, first element are the mean normalized examples (pandas DataFrame), second\n",
    "     element are the corresponding labels (pandas Series).\n",
    "    \"\"\"\n",
    "\n",
    "    examples_path = 'Extracted_Features-' + dataset_name[0]\n",
    "    # unpickles and mean normalizes examples\n",
    "    examples = mean_normalize(pd.read_pickle(examples_path))\n",
    "\n",
    "    # unpickles labels\n",
    "    labels_path = 'Extracted_Features-' + dataset_name[1]\n",
    "    labels = pd.read_pickle(labels_path)\n",
    "\n",
    "    return examples, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for hyperparameter searching\n",
    "def test_run():\n",
    "    # unpickle and prepare training data\n",
    "    \n",
    "    #code to read the data from s3 bucket\n",
    "    session = boto3.session.Session(region_name='us-east-1')\n",
    "    s3client = session.client('s3')\n",
    "\n",
    "    response = s3client.get_object(Bucket='sound25', Key='Extracted_Features-notFold10_features.pkl')\n",
    "    body_string = response['Body'].read()\n",
    "    training_examples_data = cPickle.loads(body_string) \n",
    "    training_examples = mean_normalize(training_examples_data)\n",
    "    \n",
    "    response = s3client.get_object(Bucket='sound25', Key='Extracted_Features-notFold10_labels.pkl')\n",
    "    body_string = response['Body'].read()\n",
    "    training_labels_data = cPickle.loads(body_string)\n",
    "    training_labels = training_labels_data\n",
    "\n",
    "    # unpickle and prepare validation data\n",
    "    response = s3client.get_object(Bucket='sound25', Key='Extracted_Features-fold10_features.pkl')\n",
    "    body_string = response['Body'].read()\n",
    "    validation_examples_data = cPickle.loads(body_string)\n",
    "    validation_examples = mean_normalize(validation_examples_data)\n",
    "    \n",
    "    response = s3client.get_object(Bucket='sound25', Key='Extracted_Features-fold10_labels.pkl')\n",
    "    body_string = response['Body'].read()\n",
    "    \n",
    "    validation_labels_data = cPickle.loads(body_string)\n",
    "    validation_labels = validation_labels_data\n",
    "\n",
    "\n",
    "    for learning_rate in [0.001, 0.003, 0.01, 0.03, 0.1, 0.3]:\n",
    "        for regularization_strength in [0.0, 0.003, 0.03, 0.3]:\n",
    "            print(\"##########################################################################\")\n",
    "            print(\"Learning rate:\", learning_rate)\n",
    "            print(\"Regularization:\", regularization_strength)\n",
    "            train_nn_classification_model(\n",
    "                learning_rate=0.003,\n",
    "                regularization_strength=0.2,\n",
    "                steps=10000,\n",
    "                batch_size=32,\n",
    "                hidden_units=[120],\n",
    "                training_examples=training_examples,\n",
    "                training_labels=training_labels,\n",
    "                validation_examples=validation_examples,\n",
    "                validation_labels=validation_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########################################################################\n",
      "Learning rate: 0.001\n",
      "Regularization: 0.0\n",
      "Training model...\n",
      "LogLoss error (on validation data):\n",
      "here\n",
      "  period 00 : 11.84\n",
      "here\n",
      "  period 01 : 11.18\n",
      "here\n",
      "  period 02 : 11.22\n",
      "here\n",
      "  period 03 : 10.61\n",
      "here\n",
      "  period 04 : 10.52\n",
      "here\n",
      "  period 05 : 10.48\n",
      "here\n",
      "  period 06 : 10.40\n",
      "here\n",
      "  period 07 : 10.23\n",
      "here\n",
      "  period 08 : 10.19\n",
      "here\n",
      "  period 09 : 9.82\n",
      "Model training finished.\n",
      "Final accuracy (on validation data): 0.72\n",
      "##########################################################################\n",
      "Learning rate: 0.001\n",
      "Regularization: 0.003\n",
      "Training model...\n",
      "LogLoss error (on validation data):\n",
      "here\n",
      "  period 00 : 11.35\n",
      "here\n",
      "  period 01 : 10.69\n",
      "here\n",
      "  period 02 : 10.32\n",
      "here\n",
      "  period 03 : 10.15\n",
      "here\n",
      "  period 04 : 10.23\n",
      "here\n",
      "  period 05 : 9.94\n",
      "here\n",
      "  period 06 : 9.78\n",
      "here\n",
      "  period 07 : 10.03\n",
      "here\n",
      "  period 08 : 9.86\n",
      "here\n",
      "  period 09 : 9.90\n",
      "Model training finished.\n",
      "Final accuracy (on validation data): 0.71\n",
      "##########################################################################\n",
      "Learning rate: 0.001\n",
      "Regularization: 0.03\n",
      "Training model...\n",
      "LogLoss error (on validation data):\n",
      "here\n",
      "  period 00 : 11.72\n",
      "here\n",
      "  period 01 : 10.85\n",
      "here\n",
      "  period 02 : 10.40\n",
      "here\n",
      "  period 03 : 10.61\n",
      "here\n",
      "  period 04 : 10.27\n",
      "here\n",
      "  period 05 : 10.27\n",
      "here\n",
      "  period 06 : 10.19\n",
      "here\n",
      "  period 07 : 10.15\n",
      "here\n",
      "  period 08 : 10.19\n",
      "here\n",
      "  period 09 : 10.11\n",
      "Model training finished.\n",
      "Final accuracy (on validation data): 0.71\n",
      "##########################################################################\n",
      "Learning rate: 0.001\n",
      "Regularization: 0.3\n",
      "Training model...\n",
      "LogLoss error (on validation data):\n",
      "here\n",
      "  period 00 : 11.84\n",
      "here\n",
      "  period 01 : 11.55\n",
      "here\n",
      "  period 02 : 11.47\n",
      "here\n",
      "  period 03 : 11.18\n",
      "here\n",
      "  period 04 : 10.85\n",
      "here\n",
      "  period 05 : 10.69\n",
      "here\n",
      "  period 06 : 10.52\n",
      "here\n",
      "  period 07 : 10.40\n",
      "here\n",
      "  period 08 : 10.44\n",
      "here\n",
      "  period 09 : 10.48\n",
      "Model training finished.\n",
      "Final accuracy (on validation data): 0.70\n",
      "##########################################################################\n",
      "Learning rate: 0.003\n",
      "Regularization: 0.0\n",
      "Training model...\n",
      "LogLoss error (on validation data):\n",
      "here\n",
      "  period 00 : 11.31\n",
      "here\n",
      "  period 01 : 10.89\n",
      "here\n",
      "  period 02 : 10.65\n",
      "here\n",
      "  period 03 : 10.69\n",
      "here\n",
      "  period 04 : 10.77\n",
      "here\n",
      "  period 05 : 10.48\n",
      "here\n",
      "  period 06 : 10.69\n",
      "here\n",
      "  period 07 : 10.36\n",
      "here\n",
      "  period 08 : 10.65\n",
      "here\n",
      "  period 09 : 10.69\n",
      "Model training finished.\n",
      "Final accuracy (on validation data): 0.69\n",
      "##########################################################################\n",
      "Learning rate: 0.003\n",
      "Regularization: 0.003\n",
      "Training model...\n",
      "LogLoss error (on validation data):\n",
      "here\n",
      "  period 00 : 12.05\n",
      "here\n",
      "  period 01 : 10.89\n",
      "here\n",
      "  period 02 : 10.85\n",
      "here\n",
      "  period 03 : 10.65\n",
      "here\n",
      "  period 04 : 10.48\n",
      "here\n",
      "  period 05 : 10.40\n",
      "here\n",
      "  period 06 : 10.36\n",
      "here\n",
      "  period 07 : 10.44\n",
      "here\n",
      "  period 08 : 10.27\n",
      "here\n",
      "  period 09 : 10.27\n",
      "Model training finished.\n",
      "Final accuracy (on validation data): 0.70\n",
      "##########################################################################\n",
      "Learning rate: 0.003\n",
      "Regularization: 0.03\n",
      "Training model...\n",
      "LogLoss error (on validation data):\n",
      "here\n",
      "  period 00 : 11.55\n",
      "here\n",
      "  period 01 : 11.06\n",
      "here\n",
      "  period 02 : 10.81\n",
      "here\n",
      "  period 03 : 10.44\n",
      "here\n",
      "  period 04 : 10.65\n",
      "here\n",
      "  period 05 : 10.19\n",
      "here\n",
      "  period 06 : 10.15\n",
      "here\n",
      "  period 07 : 10.52\n",
      "here\n",
      "  period 08 : 10.40\n",
      "here\n",
      "  period 09 : 10.52\n",
      "Model training finished.\n",
      "Final accuracy (on validation data): 0.70\n",
      "##########################################################################\n",
      "Learning rate: 0.003\n",
      "Regularization: 0.3\n",
      "Training model...\n",
      "LogLoss error (on validation data):\n",
      "here\n",
      "  period 00 : 10.73\n",
      "here\n",
      "  period 01 : 10.56\n",
      "here\n",
      "  period 02 : 10.23\n",
      "here\n",
      "  period 03 : 10.36\n",
      "here\n",
      "  period 04 : 10.44\n",
      "here\n",
      "  period 05 : 10.27\n",
      "here\n",
      "  period 06 : 10.19\n",
      "here\n",
      "  period 07 : 9.99\n",
      "here\n",
      "  period 08 : 10.15\n",
      "here\n",
      "  period 09 : 10.11\n",
      "Model training finished.\n",
      "Final accuracy (on validation data): 0.71\n",
      "##########################################################################\n",
      "Learning rate: 0.01\n",
      "Regularization: 0.0\n",
      "Training model...\n",
      "LogLoss error (on validation data):\n",
      "here\n",
      "  period 00 : 11.31\n",
      "here\n",
      "  period 01 : 11.14\n",
      "here\n",
      "  period 02 : 10.69\n",
      "here\n",
      "  period 03 : 10.44\n",
      "here\n",
      "  period 04 : 10.44\n",
      "here\n",
      "  period 05 : 10.36\n",
      "here\n",
      "  period 06 : 10.36\n",
      "here\n",
      "  period 07 : 10.23\n",
      "here\n",
      "  period 08 : 9.99\n",
      "here\n",
      "  period 09 : 10.23\n",
      "Model training finished.\n",
      "Final accuracy (on validation data): 0.70\n",
      "##########################################################################\n",
      "Learning rate: 0.01\n",
      "Regularization: 0.003\n",
      "Training model...\n",
      "LogLoss error (on validation data):\n",
      "here\n",
      "  period 00 : 11.97\n",
      "here\n",
      "  period 01 : 11.02\n",
      "here\n",
      "  period 02 : 10.85\n",
      "here\n",
      "  period 03 : 10.61\n",
      "here\n",
      "  period 04 : 10.81\n",
      "here\n",
      "  period 05 : 10.48\n",
      "here\n",
      "  period 06 : 10.52\n",
      "here\n",
      "  period 07 : 10.40\n",
      "here\n",
      "  period 08 : 10.23\n",
      "here\n",
      "  period 09 : 10.27\n",
      "Model training finished.\n",
      "Final accuracy (on validation data): 0.70\n",
      "##########################################################################\n",
      "Learning rate: 0.01\n",
      "Regularization: 0.03\n",
      "Training model...\n",
      "LogLoss error (on validation data):\n",
      "here\n",
      "  period 00 : 11.55\n",
      "here\n",
      "  period 01 : 10.85\n",
      "here\n",
      "  period 02 : 10.94\n",
      "here\n",
      "  period 03 : 10.89\n",
      "here\n",
      "  period 04 : 10.81\n",
      "here\n",
      "  period 05 : 10.61\n",
      "here\n",
      "  period 06 : 10.81\n",
      "here\n",
      "  period 07 : 10.89\n",
      "here\n",
      "  period 08 : 10.77\n",
      "here\n",
      "  period 09 : 10.61\n",
      "Model training finished.\n",
      "Final accuracy (on validation data): 0.69\n",
      "##########################################################################\n",
      "Learning rate: 0.01\n",
      "Regularization: 0.3\n",
      "Training model...\n",
      "LogLoss error (on validation data):\n",
      "here\n",
      "  period 00 : 11.27\n",
      "here\n",
      "  period 01 : 10.77\n",
      "here\n",
      "  period 02 : 10.52\n",
      "here\n",
      "  period 03 : 10.15\n",
      "here\n",
      "  period 04 : 10.36\n",
      "here\n",
      "  period 05 : 10.36\n",
      "here\n",
      "  period 06 : 10.27\n",
      "here\n",
      "  period 07 : 10.15\n",
      "here\n",
      "  period 08 : 10.19\n",
      "here\n",
      "  period 09 : 10.23\n",
      "Model training finished.\n",
      "Final accuracy (on validation data): 0.70\n",
      "##########################################################################\n",
      "Learning rate: 0.03\n",
      "Regularization: 0.0\n",
      "Training model...\n",
      "LogLoss error (on validation data):\n",
      "here\n",
      "  period 00 : 10.40\n",
      "here\n",
      "  period 01 : 10.27\n",
      "here\n",
      "  period 02 : 10.19\n",
      "here\n",
      "  period 03 : 10.11\n",
      "here\n",
      "  period 04 : 9.94\n",
      "here\n",
      "  period 05 : 9.86\n",
      "here\n",
      "  period 06 : 9.74\n",
      "here\n",
      "  period 07 : 9.70\n",
      "here\n",
      "  period 08 : 9.66\n",
      "here\n",
      "  period 09 : 9.74\n",
      "Model training finished.\n",
      "Final accuracy (on validation data): 0.72\n",
      "##########################################################################\n",
      "Learning rate: 0.03\n",
      "Regularization: 0.003\n",
      "Training model...\n",
      "LogLoss error (on validation data):\n",
      "here\n",
      "  period 00 : 10.89\n",
      "here\n",
      "  period 01 : 10.56\n",
      "here\n",
      "  period 02 : 10.61\n",
      "here\n",
      "  period 03 : 10.61\n",
      "here\n",
      "  period 04 : 10.44\n",
      "here\n",
      "  period 05 : 10.69\n",
      "here\n",
      "  period 06 : 10.48\n",
      "here\n",
      "  period 07 : 10.36\n",
      "here\n",
      "  period 08 : 10.44\n",
      "here\n",
      "  period 09 : 10.44\n",
      "Model training finished.\n",
      "Final accuracy (on validation data): 0.70\n",
      "##########################################################################\n",
      "Learning rate: 0.03\n",
      "Regularization: 0.03\n",
      "Training model...\n",
      "LogLoss error (on validation data):\n",
      "here\n",
      "  period 00 : 10.89\n",
      "here\n",
      "  period 01 : 10.40\n",
      "here\n",
      "  period 02 : 10.56\n",
      "here\n",
      "  period 03 : 10.61\n",
      "here\n",
      "  period 04 : 10.36\n",
      "here\n",
      "  period 05 : 10.23\n",
      "here\n",
      "  period 06 : 10.07\n",
      "here\n",
      "  period 07 : 10.11\n",
      "here\n",
      "  period 08 : 9.82\n",
      "here\n",
      "  period 09 : 9.86\n",
      "Model training finished.\n",
      "Final accuracy (on validation data): 0.71\n",
      "##########################################################################\n",
      "Learning rate: 0.03\n",
      "Regularization: 0.3\n",
      "Training model...\n",
      "LogLoss error (on validation data):\n",
      "here\n",
      "  period 00 : 10.98\n",
      "here\n",
      "  period 01 : 10.48\n",
      "here\n",
      "  period 02 : 10.23\n",
      "here\n",
      "  period 03 : 10.40\n",
      "here\n",
      "  period 04 : 10.27\n",
      "here\n",
      "  period 05 : 10.03\n",
      "here\n",
      "  period 06 : 9.90\n",
      "here\n",
      "  period 07 : 9.74\n",
      "here\n",
      "  period 08 : 9.94\n",
      "here\n",
      "  period 09 : 9.99\n",
      "Model training finished.\n",
      "Final accuracy (on validation data): 0.71\n",
      "##########################################################################\n",
      "Learning rate: 0.1\n",
      "Regularization: 0.0\n",
      "Training model...\n",
      "LogLoss error (on validation data):\n",
      "here\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "/tmp/tmp_afgoxgc/graph.pbtxt.tmpfb47f6a24f88421c869ff1ce3ea9bc16; No space left on device",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-f86ccc9500bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-23-c2e255be0b8f>\u001b[0m in \u001b[0;36mtest_run\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mtraining_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                 \u001b[0mvalidation_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_examples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m                 validation_labels=validation_labels)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-20-d7b43b5f26e9>\u001b[0m in \u001b[0;36mtrain_nn_classification_model\u001b[0;34m(learning_rate, regularization_strength, steps, batch_size, hidden_units, training_examples, training_labels, validation_examples, validation_labels, model_Name)\u001b[0m\n\u001b[1;32m     69\u001b[0m         classifier.train(\n\u001b[1;32m     70\u001b[0m             \u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_input_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_period\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         )\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dnn/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dnn/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1143\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1145\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dnn/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1171\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n\u001b[1;32m   1172\u001b[0m                                              \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1173\u001b[0;31m                                              saving_listeners)\n\u001b[0m\u001b[1;32m   1174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dnn/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_with_estimator_spec\u001b[0;34m(self, estimator_spec, worker_hooks, hooks, global_step_tensor, saving_listeners)\u001b[0m\n\u001b[1;32m   1446\u001b[0m         \u001b[0msave_summaries_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_summary_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m         \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1448\u001b[0;31m         log_step_count_steps=self._config.log_step_count_steps) as mon_sess:\n\u001b[0m\u001b[1;32m   1449\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dnn/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mMonitoredTrainingSession\u001b[0;34m(master, is_chief, checkpoint_dir, scaffold, hooks, chief_only_hooks, save_checkpoint_secs, save_summaries_steps, save_summaries_secs, config, stop_grace_period_secs, log_step_count_steps, max_wait_secs, save_checkpoint_steps, summary_dir)\u001b[0m\n\u001b[1;32m    419\u001b[0m     \u001b[0mall_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m   return MonitoredSession(session_creator=session_creator, hooks=all_hooks,\n\u001b[0;32m--> 421\u001b[0;31m                           stop_grace_period_secs=stop_grace_period_secs)\n\u001b[0m\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dnn/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, session_creator, hooks, stop_grace_period_secs)\u001b[0m\n\u001b[1;32m    830\u001b[0m     super(MonitoredSession, self).__init__(\n\u001b[1;32m    831\u001b[0m         \u001b[0msession_creator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshould_recover\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         stop_grace_period_secs=stop_grace_period_secs)\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dnn/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, session_creator, hooks, should_recover, stop_grace_period_secs)\u001b[0m\n\u001b[1;32m    553\u001b[0m         stop_grace_period_secs=stop_grace_period_secs)\n\u001b[1;32m    554\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshould_recover\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_RecoverableSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_coordinated_creator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_coordinated_creator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dnn/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sess_creator)\u001b[0m\n\u001b[1;32m   1016\u001b[0m     \"\"\"\n\u001b[1;32m   1017\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess_creator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess_creator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1018\u001b[0;31m     \u001b[0m_WrappedSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1019\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_create_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dnn/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36m_create_session\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1023\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess_creator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1024\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m         logging.info('An error was raised while a session was being created. '\n",
      "\u001b[0;32m~/anaconda3/envs/dnn/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mcreate_session\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    716\u001b[0m       \u001b[0;31m# Inform the hooks that a new session has been created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m         \u001b[0mhook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_create_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_sess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    719\u001b[0m       return _CoordinatedSession(\n\u001b[1;32m    720\u001b[0m           \u001b[0m_HookedSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_sess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoord\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dnn/lib/python3.6/site-packages/tensorflow/python/training/basic_session_run_hooks.py\u001b[0m in \u001b[0;36mafter_create_session\u001b[0;34m(self, session, coord)\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_graph_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madd_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_checkpoint_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \"graph.pbtxt\")\n\u001b[0m\u001b[1;32m    442\u001b[0m     \u001b[0msaver_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_saver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver_def\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_saver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dnn/lib/python3.6/site-packages/tensorflow/python/framework/graph_io.py\u001b[0m in \u001b[0;36mwrite_graph\u001b[0;34m(graph_or_graph_def, logdir, name, as_text)\u001b[0m\n\u001b[1;32m     69\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mas_text\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     file_io.atomic_write_string_to_file(path,\n\u001b[0;32m---> 71\u001b[0;31m                                         text_format.MessageToString(graph_def))\n\u001b[0m\u001b[1;32m     72\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mfile_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matomic_write_string_to_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dnn/lib/python3.6/site-packages/tensorflow/python/lib/io/file_io.py\u001b[0m in \u001b[0;36matomic_write_string_to_file\u001b[0;34m(filename, contents, overwrite)\u001b[0m\n\u001b[1;32m    432\u001b[0m   \"\"\"\n\u001b[1;32m    433\u001b[0m   \u001b[0mtemp_pathname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".tmp\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0muuid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muuid4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m   \u001b[0mwrite_string_to_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_pathname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_pathname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dnn/lib/python3.6/site-packages/tensorflow/python/lib/io/file_io.py\u001b[0m in \u001b[0;36mwrite_string_to_file\u001b[0;34m(filename, file_content)\u001b[0m\n\u001b[1;32m    312\u001b[0m   \"\"\"\n\u001b[1;32m    313\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mFileIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dnn/lib/python3.6/site-packages/tensorflow/python/lib/io/file_io.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, file_content)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m       pywrap_tensorflow.AppendToFile(\n\u001b[0;32m--> 111\u001b[0;31m           compat.as_bytes(file_content), self._writable_file, status)\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dnn/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    520\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: /tmp/tmp_afgoxgc/graph.pbtxt.tmpfb47f6a24f88421c869ff1ce3ea9bc16; No space left on device"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dnn2",
   "language": "python",
   "name": "dnn2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
